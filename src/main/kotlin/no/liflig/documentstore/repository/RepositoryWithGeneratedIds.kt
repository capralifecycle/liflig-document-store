package no.liflig.documentstore.repository

import no.liflig.documentstore.entity.Entity
import no.liflig.documentstore.entity.EntityId
import no.liflig.documentstore.entity.IntegerEntityId
import no.liflig.documentstore.entity.Version
import no.liflig.documentstore.entity.Versioned
import no.liflig.documentstore.utils.BatchProvider
import no.liflig.documentstore.utils.currentTimeWithMicrosecondPrecision
import no.liflig.documentstore.utils.executeBatchOperation
import org.jdbi.v3.core.Jdbi
import org.jdbi.v3.core.mapper.RowMapper

/**
 * Subclass of [RepositoryJdbi] for entities that want their IDs to be generated by the database.
 * One often wants this when using [IntegerEntityId], and the ID column is `PRIMARY KEY GENERATED BY
 * DEFAULT AS IDENTITY`. It affects how we implement [create]/[batchCreate].
 *
 * The [Entity.id] given to `create` is ignored in this class (we still require an `id` to be
 * present, since we want to use the same entity interface - you can use [IntegerEntityId.GENERATED]
 * as a temporary ID value for new entities). Instead, the database generates the ID, which is set
 * on the `id` field of the `Versioned<Entity>` returned by `create`. If you use this entity for
 * anything after creating it (such as returning it to the user), make sure to use the entity
 * returned by `create`, so that you get the actual generated ID and not the dummy value.
 *
 * Note that the `id` column cannot be `GENERATED ALWAYS` - see [create] for the reason.
 */
open class RepositoryWithGeneratedIds<EntityIdT : EntityId, EntityT : Entity<EntityIdT>>(
    jdbi: Jdbi,
    tableName: String,
    serializationAdapter: SerializationAdapter<EntityT>,
) : RepositoryJdbi<EntityIdT, EntityT>(jdbi, tableName, serializationAdapter) {
  private val entityDataMapper: RowMapper<EntityT> = EntityDataRowMapper(serializationAdapter)

  override fun create(entity: EntityT): Versioned<EntityT> {
    /**
     * (Docstring inside body, since this documents implementation details)
     *
     * We need a separate query to implement `create` for entities with database-generated IDs,
     * because these entities don't have their IDs already set when given to `create`, like we
     * assume for UUID and String IDs.
     *
     * We have an interesting challenge to solve here, because we store IDs in two places in our
     * tables: both in the `id` column, and in the `data` JSONB column (since `id` is part of the
     * [Entity] interface, so it becomes part of the JSON). When IDs are generated by the database,
     * we need to make sure that the `id` field on `data` is set correctly to the generated `id`
     * column. To achieve this, we:
     * - Use the fact that `GENERATED` columns in Postgres are backed by a _sequence_ (essentially a
     *   number generator)
     *     - We can use the
     *       [`nextval` function](https://www.postgresql.org/docs/17/functions-sequence.html) to get
     *       and reserve the next value in a sequence
     *     - And we can use the
     *       [`pg_get_serial_sequence` function](https://www.postgresql.org/docs/17/functions-info.html)
     *       to get the name of the sequence associated with a table's `GENERATED` column
     * - Now that we have gotten and reserved the next generated ID, we can use that to set both the
     *   `id` column and the `data.id` JSONB field at once in our INSERT
     *
     * Finally, we use `RETURNING data` to return the entity with the generated ID.
     *
     * This works well, though there is one drawback: since we first get the generated ID with
     * `nextval`, and then set the `id` column explicitly, we can't use `GENERATED ALWAYS` on our
     * `id` column, since that errors when we set `id` explicitly. So we must use `GENERATED BY
     * DEFAULT`, although the behavior we have here is more akin to `GENERATED ALWAYS`.
     */
    try {
      val createdAt = currentTimeWithMicrosecondPrecision()
      val version = Version.initial()

      val entityWithGeneratedId = useHandle { handle ->
        handle
            .createQuery(
                """
                      WITH generated_id AS (
                        SELECT nextval(pg_get_serial_sequence('${tableName}', 'id')) AS value
                      )
                      INSERT INTO "${tableName}" (id, data, version, created_at, modified_at)
                      SELECT
                        generated_id.value,
                        jsonb_set(:data::jsonb, '{id}', to_jsonb(generated_id.value)),
                        :version,
                        :createdAt,
                        :modifiedAt
                      FROM generated_id
                      RETURNING data
                    """
                    .trimIndent(),
            )
            .bind("data", serializationAdapter.toJson(entity))
            .bind("version", version)
            .bind("createdAt", createdAt)
            .bind("modifiedAt", createdAt)
            .map(entityDataMapper)
            .firstOrNull()
            ?: throw IllegalStateException(
                "INSERT query for entity with generated ID did not return entity data",
            )
      }

      return Versioned(entityWithGeneratedId, version, createdAt, modifiedAt = createdAt)
    } catch (e: Exception) {
      // Call mapDatabaseException first to handle connection-related exceptions, before calling
      // mapCreateOrUpdateException (which may be overridden by users for custom error handling).
      throw mapCreateOrUpdateException(mapDatabaseException(e), entity)
    }
  }

  override fun batchCreate(entities: Iterable<EntityT>): List<Versioned<EntityT>> {
    /**
     * (Docstring inside body, since this documents implementation details)
     *
     * See:
     * - [create] for the challenges with database-generated IDs, which we also face here
     * - [no.liflig.documentstore.utils.executeBatch] for how we handle returning the data from our
     *   created entities (which we need here in order to get the generated IDs)
     */
    val batchProvider = BatchProvider.fromIterable(entities)
    if (batchProvider.isEmpty()) {
      return emptyList()
    }

    val createdAt = currentTimeWithMicrosecondPrecision()

    // If we know the size of the given entities, we want to pre-allocate capacity for the result
    val size = batchProvider.totalSize()
    val entitiesWithGeneratedId: ArrayList<Versioned<EntityT>> =
        if (size != null) ArrayList(size) else ArrayList()

    transactional {
      useHandle { handle ->
        executeBatchOperation(
            handle,
            batchProvider,
            statement =
                """
                  WITH generated_id AS (
                    SELECT nextval(pg_get_serial_sequence('${tableName}', 'id')) AS value
                  )
                  INSERT INTO "${tableName}" (id, data, version, created_at, modified_at)
                  SELECT
                    generated_id.value,
                    jsonb_set(:data::jsonb, '{id}', to_jsonb(generated_id.value)),
                    :version,
                    :createdAt,
                    :modifiedAt
                  FROM generated_id
                """
                    .trimIndent(),
            bindParameters = { batch, entity ->
              batch
                  .bind("data", serializationAdapter.toJson(entity))
                  .bind("version", Version.initial())
                  .bind("createdAt", createdAt)
                  .bind("modifiedAt", createdAt)
            },
            columnsToReturn = arrayOf(Columns.DATA),
            handleReturnedColumns = { resultSet ->
              for (entityWithGeneratedId in resultSet.map(entityDataMapper)) {
                entitiesWithGeneratedId.add(
                    Versioned(
                        entityWithGeneratedId,
                        version = Version.initial(),
                        createdAt = createdAt,
                        modifiedAt = createdAt,
                    ),
                )
              }
            },
        )
      }
    }

    return entitiesWithGeneratedId
  }
}
